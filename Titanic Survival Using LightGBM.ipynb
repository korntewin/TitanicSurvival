{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-2.0.6-py2.py3-none-win_amd64.whl (987kB)\n",
      "Requirement already satisfied: numpy in d:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm)\n",
      "Requirement already satisfied: scipy in d:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm)\n",
      "Requirement already satisfied: scikit-learn in d:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Training set and Test set of Titanic Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set (891, 12)\n",
      "Shape of test set (418, 11)\n",
      "--- Null Data on train set ---\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "--- Null Data on test set ---\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "whole_train_set = pd.read_csv('train.csv')\n",
    "whole_test_set = pd.read_csv('test.csv')\n",
    "\n",
    "print('Shape of train set', whole_train_set.shape)\n",
    "print('Shape of test set', whole_test_set.shape)\n",
    "\n",
    "print('--- Null Data on train set ---\\n', whole_train_set.isnull().sum())\n",
    "print('--- Null Data on test set ---\\n', whole_test_set.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass                                               Name  \\\n",
      "0           0       3                            Braund, Mr. Owen Harris   \n",
      "1           1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2           1       3                             Heikkinen, Miss. Laina   \n",
      "3           1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "4           0       3                           Allen, Mr. William Henry   \n",
      "5           0       3                                   Moran, Mr. James   \n",
      "6           0       1                            McCarthy, Mr. Timothy J   \n",
      "7           0       3                     Palsson, Master. Gosta Leonard   \n",
      "8           1       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n",
      "9           1       2                Nasser, Mrs. Nicholas (Adele Achem)   \n",
      "10          1       3                    Sandstrom, Miss. Marguerite Rut   \n",
      "11          1       1                           Bonnell, Miss. Elizabeth   \n",
      "12          0       3                     Saundercock, Mr. William Henry   \n",
      "13          0       3                        Andersson, Mr. Anders Johan   \n",
      "14          0       3               Vestrom, Miss. Hulda Amanda Adolfina   \n",
      "15          1       2                   Hewlett, Mrs. (Mary D Kingcome)    \n",
      "16          0       3                               Rice, Master. Eugene   \n",
      "17          1       2                       Williams, Mr. Charles Eugene   \n",
      "18          0       3  Vander Planke, Mrs. Julius (Emelia Maria Vande...   \n",
      "19          1       3                            Masselmani, Mrs. Fatima   \n",
      "20          0       2                               Fynney, Mr. Joseph J   \n",
      "21          1       2                              Beesley, Mr. Lawrence   \n",
      "22          1       3                        McGowan, Miss. Anna \"Annie\"   \n",
      "23          1       1                       Sloper, Mr. William Thompson   \n",
      "24          0       3                      Palsson, Miss. Torborg Danira   \n",
      "25          1       3  Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...   \n",
      "26          0       3                            Emir, Mr. Farred Chehab   \n",
      "27          0       1                     Fortune, Mr. Charles Alexander   \n",
      "28          1       3                      O'Dwyer, Miss. Ellen \"Nellie\"   \n",
      "29          0       3                                Todoroff, Mr. Lalio   \n",
      "..        ...     ...                                                ...   \n",
      "861         0       2                        Giles, Mr. Frederick Edward   \n",
      "862         1       1  Swift, Mrs. Frederick Joel (Margaret Welles Ba...   \n",
      "863         0       3                  Sage, Miss. Dorothy Edith \"Dolly\"   \n",
      "864         0       2                             Gill, Mr. John William   \n",
      "865         1       2                           Bystrom, Mrs. (Karolina)   \n",
      "866         1       2                       Duran y More, Miss. Asuncion   \n",
      "867         0       1               Roebling, Mr. Washington Augustus II   \n",
      "868         0       3                        van Melkebeke, Mr. Philemon   \n",
      "869         1       3                    Johnson, Master. Harold Theodor   \n",
      "870         0       3                                  Balkic, Mr. Cerin   \n",
      "871         1       1   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)   \n",
      "872         0       1                           Carlsson, Mr. Frans Olof   \n",
      "873         0       3                        Vander Cruyssen, Mr. Victor   \n",
      "874         1       2              Abelson, Mrs. Samuel (Hannah Wizosky)   \n",
      "875         1       3                   Najib, Miss. Adele Kiamie \"Jane\"   \n",
      "876         0       3                      Gustafsson, Mr. Alfred Ossian   \n",
      "877         0       3                               Petroff, Mr. Nedelio   \n",
      "878         0       3                                 Laleff, Mr. Kristo   \n",
      "879         1       1      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)   \n",
      "880         1       2       Shelley, Mrs. William (Imanita Parrish Hall)   \n",
      "881         0       3                                 Markun, Mr. Johann   \n",
      "882         0       3                       Dahlberg, Miss. Gerda Ulrika   \n",
      "883         0       2                      Banfield, Mr. Frederick James   \n",
      "884         0       3                             Sutehall, Mr. Henry Jr   \n",
      "885         0       3               Rice, Mrs. William (Margaret Norton)   \n",
      "886         0       2                              Montvila, Rev. Juozas   \n",
      "887         1       1                       Graham, Miss. Margaret Edith   \n",
      "888         0       3           Johnston, Miss. Catherine Helen \"Carrie\"   \n",
      "889         1       1                              Behr, Mr. Karl Howell   \n",
      "890         0       3                                Dooley, Mr. Patrick   \n",
      "\n",
      "        Sex   Age  SibSp  Parch      Fare        Cabin Embarked  \n",
      "0      male  22.0      1      0    7.2500          NaN        S  \n",
      "1    female  38.0      1      0   71.2833          C85        C  \n",
      "2    female  26.0      0      0    7.9250          NaN        S  \n",
      "3    female  35.0      1      0   53.1000         C123        S  \n",
      "4      male  35.0      0      0    8.0500          NaN        S  \n",
      "5      male   NaN      0      0    8.4583          NaN        Q  \n",
      "6      male  54.0      0      0   51.8625          E46        S  \n",
      "7      male   2.0      3      1   21.0750          NaN        S  \n",
      "8    female  27.0      0      2   11.1333          NaN        S  \n",
      "9    female  14.0      1      0   30.0708          NaN        C  \n",
      "10   female   4.0      1      1   16.7000           G6        S  \n",
      "11   female  58.0      0      0   26.5500         C103        S  \n",
      "12     male  20.0      0      0    8.0500          NaN        S  \n",
      "13     male  39.0      1      5   31.2750          NaN        S  \n",
      "14   female  14.0      0      0    7.8542          NaN        S  \n",
      "15   female  55.0      0      0   16.0000          NaN        S  \n",
      "16     male   2.0      4      1   29.1250          NaN        Q  \n",
      "17     male   NaN      0      0   13.0000          NaN        S  \n",
      "18   female  31.0      1      0   18.0000          NaN        S  \n",
      "19   female   NaN      0      0    7.2250          NaN        C  \n",
      "20     male  35.0      0      0   26.0000          NaN        S  \n",
      "21     male  34.0      0      0   13.0000          D56        S  \n",
      "22   female  15.0      0      0    8.0292          NaN        Q  \n",
      "23     male  28.0      0      0   35.5000           A6        S  \n",
      "24   female   8.0      3      1   21.0750          NaN        S  \n",
      "25   female  38.0      1      5   31.3875          NaN        S  \n",
      "26     male   NaN      0      0    7.2250          NaN        C  \n",
      "27     male  19.0      3      2  263.0000  C23 C25 C27        S  \n",
      "28   female   NaN      0      0    7.8792          NaN        Q  \n",
      "29     male   NaN      0      0    7.8958          NaN        S  \n",
      "..      ...   ...    ...    ...       ...          ...      ...  \n",
      "861    male  21.0      1      0   11.5000          NaN        S  \n",
      "862  female  48.0      0      0   25.9292          D17        S  \n",
      "863  female   NaN      8      2   69.5500          NaN        S  \n",
      "864    male  24.0      0      0   13.0000          NaN        S  \n",
      "865  female  42.0      0      0   13.0000          NaN        S  \n",
      "866  female  27.0      1      0   13.8583          NaN        C  \n",
      "867    male  31.0      0      0   50.4958          A24        S  \n",
      "868    male   NaN      0      0    9.5000          NaN        S  \n",
      "869    male   4.0      1      1   11.1333          NaN        S  \n",
      "870    male  26.0      0      0    7.8958          NaN        S  \n",
      "871  female  47.0      1      1   52.5542          D35        S  \n",
      "872    male  33.0      0      0    5.0000  B51 B53 B55        S  \n",
      "873    male  47.0      0      0    9.0000          NaN        S  \n",
      "874  female  28.0      1      0   24.0000          NaN        C  \n",
      "875  female  15.0      0      0    7.2250          NaN        C  \n",
      "876    male  20.0      0      0    9.8458          NaN        S  \n",
      "877    male  19.0      0      0    7.8958          NaN        S  \n",
      "878    male   NaN      0      0    7.8958          NaN        S  \n",
      "879  female  56.0      0      1   83.1583          C50        C  \n",
      "880  female  25.0      0      1   26.0000          NaN        S  \n",
      "881    male  33.0      0      0    7.8958          NaN        S  \n",
      "882  female  22.0      0      0   10.5167          NaN        S  \n",
      "883    male  28.0      0      0   10.5000          NaN        S  \n",
      "884    male  25.0      0      0    7.0500          NaN        S  \n",
      "885  female  39.0      0      5   29.1250          NaN        Q  \n",
      "886    male  27.0      0      0   13.0000          NaN        S  \n",
      "887  female  19.0      0      0   30.0000          B42        S  \n",
      "888  female   NaN      1      2   23.4500          NaN        S  \n",
      "889    male  26.0      0      0   30.0000         C148        C  \n",
      "890    male  32.0      0      0    7.7500          NaN        Q  \n",
      "\n",
      "[891 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# drop passengers ID\n",
    "drop_col = ['PassengerId', 'Ticket']\n",
    "train_drop_set = whole_train_set.drop(drop_col, axis = 1)\n",
    "test_drop_set = whole_test_set.drop(drop_col, axis = 1)\n",
    "\n",
    "print(train_drop_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEFCAYAAAAPCDf9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni74kFcSiL0kFsehLUkH+PxuJ5p4YXs7mAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20a48837080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEFCAYAAAAPCDf9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfUlqEIu+JDWIRV+SGuT/A3Dz9a7LI0wIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20a484b9588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## plot age distribution\n",
    "%matplotlib inline\n",
    "age_train_data = train_drop_set.loc[np.logical_not(train_drop_set.Age.isnull()),'Age']\n",
    "age_test_data = test_drop_set.loc[np.logical_not(test_drop_set.Age.isnull()), 'Age']\n",
    "\n",
    "fig = plt.figure()\n",
    "age_train_data.plot.hist(bins = 30)\n",
    "plt.title('Age Distribution')\n",
    "\n",
    "fig = plt.figure()\n",
    "age_test_data.plot.hist(bins = 30)\n",
    "plt.title('Age Distribution')\n",
    "\n",
    "## drop age due to too many missing age\n",
    "train_drop_age_set = train_drop_set.drop(['Age'], axis = 1)\n",
    "test_drop_age_set = test_drop_set.drop(['Age'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Cabin       0\n",
      "Embarked    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Deal with missing value of cabin\n",
    "## missing value mean that this person don't have cabin to stay.\n",
    "train_cabin_set = train_drop_age_set.copy()\n",
    "train_cabin_set.loc[train_cabin_set.Cabin.isnull(),'Cabin'] = 'N'\n",
    "\n",
    "test_cabin_set = test_drop_age_set.copy()\n",
    "test_cabin_set.loc[test_cabin_set.Cabin.isnull(), 'Cabin'] = 'N'\n",
    "\n",
    "## Deal with room number of categories A, B and the other\n",
    "train_cabin_set.Cabin = train_cabin_set.Cabin.apply(lambda x: x[0])\n",
    "test_cabin_set.Cabin = test_cabin_set.Cabin.apply(lambda x: x[0])\n",
    "\n",
    "print(train_cabin_set.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n",
      "Survived    0\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Cabin       0\n",
      "Embarked    0\n",
      "dtype: int64\n",
      "Pclass      0\n",
      "Name        0\n",
      "Sex         0\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "Cabin       0\n",
      "Embarked    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Deal with missing values of Embarked in training set and missing value of Fare in test set\n",
    "print(train_cabin_set.Embarked.value_counts())\n",
    "train_set_temp = train_cabin_set.copy()\n",
    "train_set_temp.loc[train_set_temp.Embarked.isnull(), 'Embarked'] = 'S'\n",
    "\n",
    "test_set_temp = test_cabin_set.copy()\n",
    "median = np.median(test_set_temp.loc[np.logical_not(test_set_temp.Fare.isnull()),'Fare'])\n",
    "test_set_temp.loc[test_set_temp.Fare.isnull(), 'Fare'] = median\n",
    "\n",
    "print(train_set_temp.isnull().sum())\n",
    "print(test_set_temp.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' Lady': 0, ' Don': 1, ' Dr': 2, ' Dona': 3, ' Miss': 4, ' Rev': 5, ' Col': 6, ' Mme': 7, ' Major': 8, ' Capt': 9, ' Mrs': 10, ' Mr': 11, ' Mlle': 12, ' Sir': 13, ' the Countess': 14, ' Master': 15, ' Jonkheer': 16, ' Ms': 17}\n",
      "Survived        0\n",
      "Pclass          0\n",
      "Sex             0\n",
      "SibSp           0\n",
      "Parch           0\n",
      "Fare            0\n",
      "Cabin           0\n",
      "Embarked        0\n",
      "Name_Numeric    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Convert name features into number feature\n",
    "\n",
    "# for train set\n",
    "name_split = train_set_temp['Name'].map(lambda x: x.split(','))\n",
    "name_split_temp = name_split.map(lambda x: x[1].split('.'))\n",
    "train_abb_name = name_split_temp.map(lambda x: x[0])\n",
    "train_abb_name_unique = train_abb_name.unique()\n",
    "\n",
    "# for test set\n",
    "name_split = test_set_temp['Name'].map(lambda x: x.split(','))\n",
    "name_split_temp = name_split.map(lambda x: x[1].split('.'))\n",
    "test_abb_name = name_split_temp.map(lambda x: x[0])\n",
    "test_abb_name_unique = test_abb_name.unique()\n",
    "\n",
    "union_unique = set(list(train_abb_name_unique)).union(set(list(test_abb_name_unique)))\n",
    "\n",
    "# create convert dict\n",
    "dict_mr = {}\n",
    "for i, col in enumerate(union_unique):\n",
    "    dict_mr[col] = int(i)\n",
    "print(dict_mr)\n",
    "\n",
    "train_abb_name_numeric = train_abb_name.map(dict_mr)\n",
    "test_abb_name_numeric = test_abb_name.map(dict_mr)\n",
    "\n",
    "train_set_temp['Name_Numeric'] = train_abb_name_numeric\n",
    "#test_abb_name_numeric[test_abb_name_numeric.isnull()] = 0 \n",
    "#test_abb_name_numeric = test_abb_name_numeric.map(lambda x : int(x))\n",
    "test_set_temp['Name_Numeric'] = test_abb_name_numeric\n",
    "\n",
    "train_drop_name_set = train_set_temp.drop(['Name'], axis = 1)\n",
    "test_drop_name_set = test_set_temp.drop(['Name'], axis = 1)\n",
    "\n",
    "print(train_drop_name_set.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features\n",
      " Cabin_A            0\n",
      "Cabin_B            0\n",
      "Cabin_C            0\n",
      "Cabin_D            0\n",
      "Cabin_E            0\n",
      "Cabin_F            0\n",
      "Cabin_G            0\n",
      "Cabin_N            0\n",
      "Cabin_T            0\n",
      "Embarked_C         0\n",
      "Embarked_Q         0\n",
      "Embarked_S         0\n",
      "Fare               0\n",
      "Name_Numeric_0     0\n",
      "Name_Numeric_1     0\n",
      "Name_Numeric_10    0\n",
      "Name_Numeric_11    0\n",
      "Name_Numeric_12    0\n",
      "Name_Numeric_13    0\n",
      "Name_Numeric_14    0\n",
      "Name_Numeric_15    0\n",
      "Name_Numeric_16    0\n",
      "Name_Numeric_17    0\n",
      "Name_Numeric_2     0\n",
      "Name_Numeric_3     0\n",
      "Name_Numeric_4     0\n",
      "Name_Numeric_5     0\n",
      "Name_Numeric_6     0\n",
      "Name_Numeric_7     0\n",
      "Name_Numeric_8     0\n",
      "Name_Numeric_9     0\n",
      "Parch_0            0\n",
      "Parch_1            0\n",
      "Parch_2            0\n",
      "Parch_3            0\n",
      "Parch_4            0\n",
      "Parch_5            0\n",
      "Parch_6            0\n",
      "Parch_9            0\n",
      "Pclass_1           0\n",
      "Pclass_2           0\n",
      "Pclass_3           0\n",
      "Sex_female         0\n",
      "Sex_male           0\n",
      "SibSp_0            0\n",
      "SibSp_1            0\n",
      "SibSp_2            0\n",
      "SibSp_3            0\n",
      "SibSp_4            0\n",
      "SibSp_5            0\n",
      "SibSp_8            0\n",
      "Survived           0\n",
      "dtype: int64\n",
      "test features\n",
      " Cabin_A            0\n",
      "Cabin_B            0\n",
      "Cabin_C            0\n",
      "Cabin_D            0\n",
      "Cabin_E            0\n",
      "Cabin_F            0\n",
      "Cabin_G            0\n",
      "Cabin_N            0\n",
      "Cabin_T            0\n",
      "Embarked_C         0\n",
      "Embarked_Q         0\n",
      "Embarked_S         0\n",
      "Fare               0\n",
      "Name_Numeric_0     0\n",
      "Name_Numeric_1     0\n",
      "Name_Numeric_10    0\n",
      "Name_Numeric_11    0\n",
      "Name_Numeric_12    0\n",
      "Name_Numeric_13    0\n",
      "Name_Numeric_14    0\n",
      "Name_Numeric_15    0\n",
      "Name_Numeric_16    0\n",
      "Name_Numeric_17    0\n",
      "Name_Numeric_2     0\n",
      "Name_Numeric_3     0\n",
      "Name_Numeric_4     0\n",
      "Name_Numeric_5     0\n",
      "Name_Numeric_6     0\n",
      "Name_Numeric_7     0\n",
      "Name_Numeric_8     0\n",
      "Name_Numeric_9     0\n",
      "Parch_0            0\n",
      "Parch_1            0\n",
      "Parch_2            0\n",
      "Parch_3            0\n",
      "Parch_4            0\n",
      "Parch_5            0\n",
      "Parch_6            0\n",
      "Parch_9            0\n",
      "Pclass_1           0\n",
      "Pclass_2           0\n",
      "Pclass_3           0\n",
      "Sex_female         0\n",
      "Sex_male           0\n",
      "SibSp_0            0\n",
      "SibSp_1            0\n",
      "SibSp_2            0\n",
      "SibSp_3            0\n",
      "SibSp_4            0\n",
      "SibSp_5            0\n",
      "SibSp_8            0\n",
      "Survived           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## convert all category features into dummies feature\n",
    "train_set_copy = train_drop_name_set.copy()\n",
    "test_set_copy = test_drop_name_set.copy()\n",
    "\n",
    "col_indicator = ['Pclass', 'Name_Numeric', 'Sex', 'SibSp', 'Parch', 'Cabin', 'Embarked']\n",
    "\n",
    "for col in col_indicator:\n",
    "    train_set_copy = pd.get_dummies(train_set_copy, columns = [col])\n",
    "    test_set_copy = pd.get_dummies(test_set_copy, columns = [col])\n",
    "    \n",
    "## Number of headers in train and test set are not equal.\n",
    "## This has to be resolve\n",
    "\n",
    "all_header = set(list(train_set_copy)).union(set(list(test_set_copy)))\n",
    "\n",
    "for col in all_header:\n",
    "    \n",
    "    if col not in list(train_set_copy):\n",
    "        train_set_copy[col] = np.zeros(train_set_copy.loc[:,list(train_set_copy)[0]].shape)\n",
    "    elif col not in list(test_set_copy):\n",
    "        test_set_copy[col] = np.zeros(test_set_copy.loc[:,list(test_set_copy)[0]].shape)\n",
    "\n",
    "## sort index \n",
    "train_set_copy.sort_index(axis = 1, inplace = True)\n",
    "test_set_copy.sort_index(axis = 1, inplace = True)\n",
    "print('train features\\n',train_set_copy.isnull().sum())\n",
    "print('test features\\n',test_set_copy.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test 0.05070003046569588\n",
      "std test 1.0180356352070383\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD3CAYAAAD/oDhxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGEiSgP8D5fxM4ad+tHsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20a48c15208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Normalize Fare feature\n",
    "train_set_normalize = train_set_copy.copy()\n",
    "test_set_normalize = test_set_copy.copy()\n",
    "\n",
    "min_no_zero = np.min(train_set_normalize.loc[train_set_normalize.Fare > 0, 'Fare'])\n",
    "\n",
    "lamb = min_no_zero/2\n",
    "\n",
    "train_set_normalize.Fare = train_set_normalize.Fare.apply(lambda x : np.log(x + lamb))\n",
    "test_set_normalize.Fare = test_set_normalize.Fare.apply(lambda x : np.log(x + lamb))\n",
    "\n",
    "'''\n",
    "lamb = 0.3\n",
    "train_set_normalize.Fare = train_set_normalize.Fare.apply(lambda x : (x**lamb - 1)/lamb)\n",
    "test_set_normalize.Fare = test_set_normalize.Fare.apply(lambda x : (x**lamb - 1)/lamb)\n",
    "'''\n",
    "mean_train = np.mean(train_set_normalize.Fare)\n",
    "std_train = np.std(train_set_normalize.Fare)\n",
    "\n",
    "fig = plt.figure()\n",
    "test_set_normalize.Fare.plot.hist(bins = 30)\n",
    "\n",
    "## Begin normalize features\n",
    "test_set_normalize.Fare = (test_set_normalize.Fare - mean_train)/std_train\n",
    "train_set_normalize.Fare = (train_set_normalize.Fare - mean_train)/std_train\n",
    "\n",
    "print('mean test', np.mean(test_set_normalize.Fare))\n",
    "print('std test', np.std(test_set_normalize.Fare))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light Gradient Boost Tree Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (51, 891)\n",
      "X_test shape (51, 418)\n",
      "Y_train shape (891,)\n"
     ]
    }
   ],
   "source": [
    "## Extract survived featrue from train set\n",
    "train_set_extract = train_set_normalize.drop(['Survived'], axis = 1)\n",
    "test_set_extract = test_set_normalize.drop(['Survived'], axis = 1)\n",
    "\n",
    "X = train_set_extract.as_matrix().T\n",
    "X_test = test_set_extract.as_matrix().T\n",
    "Y = train_set_normalize.Survived.as_matrix()\n",
    "\n",
    "print('X_train shape', X.shape)\n",
    "print('X_test shape', X_test.shape)\n",
    "print('Y_train shape', Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples of splited data 891\n"
     ]
    }
   ],
   "source": [
    "## simple split train data to 80/20\n",
    "ratio = 0.9\n",
    "\n",
    "m = X.shape[1]\n",
    "X_train = X[:, 0:round(ratio*m)]\n",
    "X_dev = X[:,round(ratio*m):]\n",
    "\n",
    "Y_train = Y[0:round(ratio*m)]\n",
    "Y_dev = Y[round(ratio*m):]\n",
    "\n",
    "print('total samples of splited data', X_train.shape[1] + X_dev.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## specify lgb\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train.T, Y_train.T)\n",
    "lgb_eval = lgb.Dataset(X_dev.T, Y_dev.T, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'l2','binary_logloss'},\n",
    "    'num_leaves': 100,\n",
    "    'learning_rate': 0.02,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train lgb model\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=400,\n",
    "                valid_sets=lgb_eval,\n",
    "               verbose_eval = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Survived': array([ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
      "        0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
      "        1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "        1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
      "        1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
      "        1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,\n",
      "        0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,\n",
      "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
      "        1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
      "        1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,\n",
      "        1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
      "        0.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
      "        1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,\n",
      "        0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "        0.,  0.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,\n",
      "        0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
      "        0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "        1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
      "        0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
      "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "        0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,\n",
      "        0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,\n",
      "        1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
      "        1.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,\n",
      "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
      "        0.,  1.])}\n"
     ]
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test.T, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "Y_pred = np.array([round(x) for x in y_pred])\n",
    "dic = {'Survived':Y_pred}\n",
    "\n",
    "output = pd.DataFrame(dic)\n",
    "output.to_csv('Output.csv')\n",
    "\n",
    "print(dic)\n",
    "#print('The accuracy of prediction is:', accuracy_score(Y_dev, Y_pred))\n",
    "\n",
    "#print('Feature importances:', list(gbm.feature_importance()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Split Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_split(X,Y, num_fold = 10):\n",
    "    \n",
    "    '''\n",
    "    Split X and Y to num_fold\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    X_temp = X.copy()\n",
    "    Y_temp = Y.copy()\n",
    "    \n",
    "    permute_index = np.random.permutation(m)\n",
    "    \n",
    "    X_temp = X_temp[:, permute_index]\n",
    "    Y_temp = Y_temp[permute_index]\n",
    "    \n",
    "    X_fold = np.array_split(X_temp, num_fold, axis = 1)\n",
    "    Y_fold = np.array_split(Y_temp, num_fold)\n",
    "    \n",
    "    X_out = []\n",
    "    Y_out = []\n",
    "    \n",
    "    for i in range(num_fold):\n",
    "        X_dev_out = X_fold[i]\n",
    "        Y_dev_out = Y_fold[i]\n",
    "        \n",
    "        count = 0\n",
    "        for k in range(num_fold):\n",
    "            \n",
    "            if k != i:\n",
    "                count += 1\n",
    "                if count == 1:\n",
    "                    X_train_out = X_fold[k]\n",
    "                    Y_train_out = Y_fold[k]\n",
    "                else:\n",
    "                    X_train_out = np.concatenate((X_train_out, X_fold[k]), axis = 1)\n",
    "                    Y_train_out = np.concatenate((Y_train_out, Y_fold[k]))\n",
    "    \n",
    "        X_out.append((X_train_out, X_dev_out))\n",
    "        Y_out.append((Y_train_out.reshape(1, len(Y_train_out)), Y_dev_out.reshape(1, len(Y_dev_out))))\n",
    "    \n",
    "    return X_out, Y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 801)\n",
      "(1, 90)\n"
     ]
    }
   ],
   "source": [
    "X_fold, Y_fold = random_split(X, Y)\n",
    "print(X_fold[0][0].shape)\n",
    "print(Y_fold[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate(X, Y, num_fold = 10, num_hyper = 10, print_cost = True):\n",
    "    \n",
    "    X_fold, Y_fold = random_split(X, Y, num_fold = num_fold)\n",
    "    \n",
    "    result_validate = pd.DataFrame({})\n",
    "    num_leaves = np.round(np.random.rand(num_hyper,1)*200 + 31)\n",
    "    print(num_leaves)\n",
    "    \n",
    "    for k in range(num_hyper):\n",
    "        \n",
    "        dev_acc = []\n",
    "        dic = {}\n",
    "        nn = int(num_leaves[k])\n",
    "        print(nn)\n",
    "        \n",
    "        for i in range(num_fold):\n",
    "\n",
    "            X_train = X_fold[i][0]\n",
    "            X_dev = X_fold[i][1]\n",
    "\n",
    "            Y_train = np.squeeze(Y_fold[i][0])\n",
    "            Y_dev = np.squeeze(Y_fold[i][1])\n",
    "\n",
    "            lgb_train = lgb.Dataset(X_train.T, Y_train.T)\n",
    "            lgb_eval = lgb.Dataset(X_dev.T, Y_dev.T, reference=lgb_train)\n",
    "\n",
    "            # specify your configurations as a dict\n",
    "            params = {\n",
    "                'task': 'train',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric': {'l2','binary_logloss'},\n",
    "                'num_leaves': nn,\n",
    "                'learning_rate': 0.02,\n",
    "                'feature_fraction': 0.9,\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 5,\n",
    "                'verbose': 0\n",
    "            }\n",
    "\n",
    "            gbm = lgb.train(params,\n",
    "                            lgb_train,\n",
    "                            num_boost_round=400,\n",
    "                            valid_sets=lgb_eval,\n",
    "                            verbose_eval = False)\n",
    "\n",
    "            y_pred = gbm.predict(X_dev.T, num_iteration=gbm.best_iteration)\n",
    "            Y_pred = np.array([round(x) for x in y_pred])\n",
    "\n",
    "            dev_acc.append(accuracy_score(Y_dev, Y_pred))\n",
    "\n",
    "            if print_cost:\n",
    "                print('-- round ' + str(i) +' --')\n",
    "                print('The accuracy of prediction is:', accuracy_score(Y_dev, Y_pred))\n",
    "\n",
    "        mean = np.mean(dev_acc)\n",
    "        std = np.std(dev_acc)\n",
    "        dev_acc.append(mean)\n",
    "        dev_acc.append(std)\n",
    "\n",
    "        dic['model_' + str(k)] = dev_acc\n",
    "\n",
    "        result_validate = pd.concat([result_validate, pd.DataFrame(dic)], axis = 1, ignore_index = True)\n",
    "        print(result_validate)\n",
    "    \n",
    "    ## Create row index\n",
    "    row_dic = {}\n",
    "    row_index = []\n",
    "    for i in range(num_fold):\n",
    "        row_index.append('fold_'+str(i))\n",
    "    \n",
    "    row_index.append('mean')\n",
    "    row_index.append('std')\n",
    "    \n",
    "    row_dic['fold'] = row_index\n",
    "    \n",
    "    result_validate = pd.concat([pd.DataFrame(row_dic), result_validate], axis = 1)\n",
    "    result_validate.set_index('fold')\n",
    "    \n",
    "    print(result_validate)\n",
    "    \n",
    "    return result_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 108.]\n",
      " [ 158.]\n",
      " [  32.]\n",
      " [ 147.]\n",
      " [ 178.]\n",
      " [ 219.]\n",
      " [ 161.]\n",
      " [ 133.]\n",
      " [ 102.]\n",
      " [  61.]]\n",
      "108\n",
      "           0\n",
      "0   0.877778\n",
      "1   0.764045\n",
      "2   0.853933\n",
      "3   0.820225\n",
      "4   0.764045\n",
      "5   0.853933\n",
      "6   0.764045\n",
      "7   0.853933\n",
      "8   0.853933\n",
      "9   0.820225\n",
      "10  0.822609\n",
      "11  0.041556\n",
      "158\n",
      "           0         1\n",
      "0   0.877778  0.877778\n",
      "1   0.764045  0.764045\n",
      "2   0.853933  0.853933\n",
      "3   0.820225  0.820225\n",
      "4   0.764045  0.764045\n",
      "5   0.853933  0.853933\n",
      "6   0.764045  0.764045\n",
      "7   0.853933  0.853933\n",
      "8   0.853933  0.853933\n",
      "9   0.820225  0.820225\n",
      "10  0.822609  0.822609\n",
      "11  0.041556  0.041556\n",
      "32\n",
      "           0         1         2\n",
      "0   0.877778  0.877778  0.877778\n",
      "1   0.764045  0.764045  0.764045\n",
      "2   0.853933  0.853933  0.853933\n",
      "3   0.820225  0.820225  0.820225\n",
      "4   0.764045  0.764045  0.764045\n",
      "5   0.853933  0.853933  0.853933\n",
      "6   0.764045  0.764045  0.764045\n",
      "7   0.853933  0.853933  0.853933\n",
      "8   0.853933  0.853933  0.853933\n",
      "9   0.820225  0.820225  0.820225\n",
      "10  0.822609  0.822609  0.822609\n",
      "11  0.041556  0.041556  0.041556\n",
      "147\n",
      "           0         1         2         3\n",
      "0   0.877778  0.877778  0.877778  0.877778\n",
      "1   0.764045  0.764045  0.764045  0.764045\n",
      "2   0.853933  0.853933  0.853933  0.853933\n",
      "3   0.820225  0.820225  0.820225  0.820225\n",
      "4   0.764045  0.764045  0.764045  0.764045\n",
      "5   0.853933  0.853933  0.853933  0.853933\n",
      "6   0.764045  0.764045  0.764045  0.764045\n",
      "7   0.853933  0.853933  0.853933  0.853933\n",
      "8   0.853933  0.853933  0.853933  0.853933\n",
      "9   0.820225  0.820225  0.820225  0.820225\n",
      "10  0.822609  0.822609  0.822609  0.822609\n",
      "11  0.041556  0.041556  0.041556  0.041556\n",
      "178\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-412-da046638d648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_fold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hyper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-411-886a9c1443f6>\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(X, Y, num_fold, num_hyper, print_cost)\u001b[0m\n\u001b[0;32m     43\u001b[0m                             \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                             \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlgb_eval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                             verbose_eval = False)\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meval_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_training_booster\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_model_from_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbooster\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_save_model_to_string\u001b[1;34m(self, num_iteration)\u001b[0m\n\u001b[0;32m   1582\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1584\u001b[1;33m             ptr_string_buffer))\n\u001b[0m\u001b[0;32m   1585\u001b[0m         \u001b[0mactual_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1586\u001b[0m         \u001b[1;34m'''if buffer length is not long enough, re-allocate a buffer'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cross_validate(X, Y, num_fold = 10, num_hyper = 10, print_cost = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
